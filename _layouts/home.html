{% include header.html %}

  {% include banner.html %}

  <div class="wrapper">

    {% include page-nav.html %}


  <section>
    <h1><a href="https://docs.google.com/document/d/1rFik-MRIHmGVGbjKY4PLC5YEd9CJzpcn0Qth9BCpHao/edit?usp=sharing">Final Report</a></h1>
    <br>

    <h1>Project Proposal</h1>
    <br>
    
    <h2>Summary</h2>
    <p>LockTransformLib will be a Concurrency Library with different implementations of mutexes, condition variables, semaphores and readers-writers locks.</p> 
    <p>I will be analysing their performance along parameters such as fairness, average latency and processor utilization with implementations of different data structures using a test suite consisting of varying workloads.</p>
    <p>If time permits, I plan on switching between implementations during execution (similar to how pthread mutexes are implemented) based on observed workload - for example between a tradition lock based to a transactions based implementation.</p>

    <h2>Background</h2>

    <p>Common multi-threaded programs have areas of contention where different threads need to access or modify a shared data structure. In such cases, concurrency management primitives like locks are used. I have used those implemented for use with Pthreads and OpenMP constructs as well as implemented these in both user- and kernel-space in 15-410.</p>
    <p>When it comes to mutexes, their implementations can be broadly divided into two types:</p>

    <ul>
      <li>Blocking: Threads are descheduled while waiting</li>
      <li>Busy-wait: Threads test shared variables repeatedly</li>
    </ul>
    <p>Based on how the lock is implemented, there are varying effects on different kinds of workloads. A busy-wait implementation has much worse effects on performance and processor utilization if all the threads using the lock are on the same core vs when the thread making progress is on a different core from those waiting for the lock. Busy-wait implementation also causes more cache-coherence related traffic when threads are distributed across cores. They also perform diffenttly based on the length of the critical section.</p>
    <p>I would like to analyse different implementations and compare them against Pthread and OpenMP implementation along at least the following dimensions for each workload:</p>
    <ul>
      <li>Processor Utilization: <ul>This refers to how many (and on which cores) and how long execution contexts on cores are active. This allows us to determine power savings aspects of the workloads</ul></li>
      <li>Performance: <ul>Speed of completion of the program, and individual threads</ul></li>
      <li>Average latency for grabbing lock <ul>How long different thread have to wait for from time of requesting lock to entering the critical section</ul></li>
    </ul>
    <p>The above dimensions will be compared for workloads varying in at least the following ways:</p>
    <ul>
      <li>Length of critical sections</li>
      <li>Number of threads and lockers</li>
      <li>Distribution of threads to cores</li>
    </ul>
    <h2>The Challenge</h2>

    <p>In order to succeed at measuring along the above dimensions, I will initially need to implement the different constructs as well as design workloads that will meaningfully test them.</p>
    <p>Implementing a measuring framework while not affecting the results will also be a challenge.</p>
    <p>I plan on having at least one implementation of each primitive using transactions instead of coarse-grained locks using Intel's TS Extensions and since I have never worked with them before, that serves as one of the major challenges as well.</p>
    <p>

    <h2>Resources</h2>

    <p>I will be using the following papers and resoruces for guidance on implementation and analysis:</p>
    <ul>
      <li><a href="http://www.cs.rochester.edu/~scott/papers/1991_TOCS_synch.pdf">Algorithms for Scalable Synchronization on Shared-Memory MultiProcessors</a><li><a href="https://www-ssl.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf">Intel TSX enabling and optimization recommendations</a></li>
      <li>Starter code for data structure implementations - Linked lists, Balanced Trees for modifications</li>
    </ul>


    <h2>Goals and Deliverables</h2>

    <p>Plan to Achieve</p>

    <ul>
      <li>Implementations of each primitive with different tradeoffs</li>
      <li>One transactions based implementation for each primitive</li>
      <li>Varying data structure implementations requireing use of the above primitives (possible using open source starter code)</li>
      <li>Varying workloads that use my primitives and the data structures</li>
      <li>Measuring harness that gives meaningful information back</li>
    </ul>

    <p>Hope to Achieve</p>

    <ul>
      <li>Adaptive locks that will switch between varying implementations based on knowledge gained from above analysis</li>
      <li>Analysing memory footprint of different implementations</li>
      <li>Analysing cache coherency related traffic of the implementations</li>
    </ul>

    <h2>Platform Choice</h2>

    <p>I plan to use the Intel Xeon Phi processors for testing and measurements (available for access in the latedays cluster.) I will be implementing the library and tests in C++.</p>


    <h2>Schedule</h2>

    <table style="width:100%">
    <tr>
      <th width="20%">Week</th>
      <th width="80%">Goal</th> 
    </tr>
    <tr>
      <td width="20%">Apr 10-16</td>
      <td width="80%">Implement basic variations of primitives, data structures using primitive library, and correctness tests using data structures</td> 
    </tr>
    <tr>
      <td width="20%">Apr 17-23</td>
      <td width="80%">Implement Transactions based versions of primitives</td> 
    </tr>
    <tr>
      <td width="20%">Apr 24-30</td>
      <td width="80%">Implement different workloads and make initial measurements</td> 
    </tr>
    <tr>
      <td width="20%">May 1-7</td>
      <td width="80%">Integrate real-world benchmarks for measurements</td> 
    </tr>
    <tr>
      <td width="20%">May 8-12</td>
      <td width="80%">Buffer time or time to implement adaptive primitives</td> 
    </tr>
    </table>

    <h1>Checkpoint</h1>
    <br>

    <h2>Progress</h2>
    <p>So far, I have been able to implement different kinds of mutexes, my own implementations and implementations from a paper that I read previously. I also tested them with multiple tests all spawning threads using openmp, and confirmed that they satisfy mutual exclusion, bounded waiting as well as progress.</p>
    <p>I also have an initial trial implementation (untested) using 1 trial transaction XBEGIN call after which any abort would require the need to hold a lock. However, because of the case where even at the point of an abort, there might be a successful thread making progress, and committing changes to memory, there are a few edge cases (like nested transactions upto an architecture determined limited) that I still need to handle and confirm with tests.</p>
    <p></p>

    <h2>Deliverables</h2>
    <p>In terms of my deliverables, I would change a bit, the ordering of the work I would like to accomplish. I aim to make my transforming locks of higher priority than implementing other types of primitives, since most other primitives can be extracted from the mutex implementation, and architecture specific, scheduling constructs. I still plan to have at least two (non-transactional or possible using the transactions based mutexes) implementation of each primitive to compare for different types, but their transformational capability will be solely based on the transformations of the mutexes (my base primitive) that I will use in their implementation.</p>
    
    <h2>Presentation</h2>
    <p> My presentation will be mostly graphs. Since I have my own tests that will show the optimality of the different types of solutions for each of the primitives, I could also possibly run one test live and show my log files with a summary at the end, live, but generating graphs live would be a stretch goal for me since that would involve parseing and UI that I am not sure I have time for in order to finish the project successfully.</p>

    <h2>Results</h2>

    <h2>Updated Schedule</h2>
    <table style="width:100%">
    <tr>
      <th width="20%">Days</th>
      <th width="80%">Goal</th> 
    </tr>
    <tr>
      <td width="20%">Apr 25-27</td>
      <td width="80%">Finish the simple and transactions based implementations for mutexes</td> 
    </tr>
    <tr>
      <td width="20%">Apr 28-30</td>
      <td width="80%">Exam study and test framework implementation</td> 
    </tr>
    <tr>
      <td width="20%">Apr 01-03</td>
      <td width="80%">Workloads, and measurements using icc and g++ on latedays and ghc machines</td> 
    </tr>
    <tr>
      <td width="20%">May 04-06</td>
      <td width="80%">Implementing transforming mutexes and comparing them for the workloads based on the results from the previous work</td> 
    </tr>
    <tr>
      <td width="20%">May 07-10</td>
      <td width="80%">Porting at least 2 different implementations for cvars, sem and rwlocks using different types of mutexes specific to the MIC architecture (Xeon Phi) and then comparing them for simple workloads</td> 
    </tr>
    <tr>
      <td width="20%">May 11-12</td>
      <td width="80%">Work on presentation</td> 
    </tr>
    </table>

    <h2>Concerns</h2>
    Some concerns I have are the following:
    <ul>
    <li>The implementation of the transactions based locks is more architecture dependent than I thought it to be previously, and I need to dig more deeply into Intel's suggestions document to understand more deeply some of the decisions taken in order to not violate any mutual exclusion properties</li>
    <li>I am also worried about the accurately implementing back-off for some of the mutex implementations which depend on proportional back-off thereby possibly causing varying results</li>
    </ul>

    </section>

	{{ content }}

{% include footer.html %}
